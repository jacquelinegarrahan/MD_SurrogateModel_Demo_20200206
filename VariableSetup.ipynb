{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data management for model inputs and outputs\n",
    "\n",
    "This notebook explores the use of xarray and pydantic classes for the management of input and output surrogate model variables. For the purpose of this demo, the data for process variables has been organized into the file: `online_model/var_config.py`; however, the intention for these methods is that they will be called directly from the model build in order to organize the process variables for subsequent server use. \n",
    "\n",
    "Three approaches will be used in organizing the model input/outputs and their metadata:\n",
    "1. Use of xarray variables\n",
    "2. Pydantic class implementation with validation\n",
    "\n",
    "Once the data has been constructed, it will be served using both the Channel Access and PVAccess servers. Here, these are converted into the appropriate dictionaries for building the process variable database items. The PVAccess server could be refactored to directly use the new data structure instead of constructing the pvdb; however, the Channel Access server uses the pvdb in its constuction so the pvdb conversion step will be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current data requirements:\n",
    "In its current iteration (as reflected by the pva_refactor branch), the server and client use the process variable database constructed from the model info keys provided in the hdf5 file associated with the model. This serves as a single source of truth composed at runtime for both client and server, which should be avoided going forward. The process variable database should instead be derived from an input/output collection that is saved along with the model build and may be replicated across model builds. Current data used client and server-side is outlined below:\n",
    "\n",
    "\n",
    "| Attribute   | Used server-side | Used client-side | Required for pva | Required for CA |\n",
    "|-------------|------------------|------------------|------------------|-----------------|\n",
    "| name        | ✓                | ✓                | ✓                | ✓               |\n",
    "| pv_type     | ✓                | ✓                | ✓                | ✓               |\n",
    "| value *     | ✓ (inputs)       |                  | ✓ (inputs)       | ✓ (inputs)      |\n",
    "| default **  |                  | ✓                |                  |                 |\n",
    "| units       |                  | ✓                |                  |                 |\n",
    "| value_range | ✓ (CA)           | ✓ (sliders)      |                  | ✓               |\n",
    "| is_input    | ✓                | ✓                | ✓                | ✓               |\n",
    "| type        | ✓ (CA)           |                  |                  | ✓               |\n",
    "| precision   | ✓ (CA)           |                  |                  | ✓               |\n",
    "\n",
    "Additionally, this collection might also be extended to encompass build instructions. This will be explored in section 3.\n",
    "\n",
    "\n",
    "\n",
    "\\* Value for outputs is not required because it is computed directly from the model before serving.\n",
    "<br>\n",
    "\\** Defaults are currently used as placeholders. There is also a concept of a missing value default for IOCs that could be acocunted for in a similar manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. xarray for metadata \n",
    "The process variables are each constructed using the `xarray.Variable` class. All variables are then used to construct a Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "# xarray does not propogate attributes by default\n",
    "xr.set_options(keep_attrs = True)\n",
    "\n",
    "def build_variable(*, \n",
    "                   name: str, \n",
    "                   pv_type: str, \n",
    "                   value: Union[np.ndarray, float], \n",
    "                   value_range: List[float], \n",
    "                   default: Union[np.ndarray, float], \n",
    "                   dim: Tuple[str], \n",
    "                   units: str, \n",
    "                   is_input: int,\n",
    "                   precision: int,\n",
    "                   color_mode: int, # None if image pv\n",
    "                   shape: Tuple[int] # None if image pv\n",
    "                  ) -> xr.Variable: \n",
    "    \n",
    "    # assign default for none value\n",
    "    if value is None:\n",
    "        value = default\n",
    "    \n",
    "    # need to convert scalar to array to work with xarray\n",
    "    if isinstance(value, (float,)):\n",
    "        value = np.array([value])\n",
    "        \n",
    "    attributes = {\n",
    "              \"pv_type\": pv_type, \n",
    "              \"range\" : value_range,\n",
    "              \"default\": default,\n",
    "              \"units\": units,\n",
    "              \"name\": name,\n",
    "              \"is_input\": is_input,\n",
    "              \"precision\": precision,\n",
    "             }\n",
    "    \n",
    "    if pv_type == \"image\":\n",
    "        attributes[\"color_mode\"] = color_mode\n",
    "        attributes[\"shape\"] = shape\n",
    "        \n",
    "    variable = xr.Variable(dim,\n",
    "                           value,\n",
    "                           attrs=attributes\n",
    "                        )\n",
    "    \n",
    "    return variable\n",
    "\n",
    "\n",
    "# Example variable using misc data\n",
    "example_variable = build_variable(\n",
    "    name = \"example\",\n",
    "    pv_type = \"scalar\",\n",
    "    value_range=[1.000000e-01, 5.000000e-01], \n",
    "    default=3.47986980e-01,\n",
    "    value= np.array([3.47986980e-01]), # MUST BE AN ARRAY!\n",
    "    dim = (\"length\",),\n",
    "    units = \"mm\",\n",
    "    is_input = 1,\n",
    "    precision = 8,\n",
    "    color_mode = None,\n",
    "    shape = None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, use the build_variable function to create xarray Dataset from our model info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_model.var_config import VARIABLES\n",
    "\n",
    "\n",
    "variables = {}\n",
    "\n",
    "for variable, configs in VARIABLES.items():\n",
    "    variables[variable] = build_variable(\n",
    "        name = variable,\n",
    "        pv_type = configs.get(\"pv_type\"),\n",
    "        value_range=configs.get(\"range\"), \n",
    "        default=configs.get(\"default\"),\n",
    "        value= configs.get(\"value\"),\n",
    "        dim = configs.get(\"xarray_dim\"),\n",
    "        units = configs.get(\"units\"),\n",
    "        is_input = configs.get(\"is_input\"),\n",
    "        precision = 8, \n",
    "        color_mode = configs.get(\"color_mode\"),\n",
    "        shape = configs.get(\"shape\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "dset = xr.Dataset(variables)\n",
    "# show dset explore view\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare to serve\n",
    "Note: Enforcing required attributes for our entry would require massive manual extension of the build_variable. This has the potential to result in missing required fields or incorrectly typed attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_model.server import ca, pva\n",
    "from online_model.model.MySurrogateModel import MySurrogateModel\n",
    "PREFIX = \"smvm\"\n",
    "\n",
    "MODEL_FILE = \"online_model/files/CNN_051620_SurrogateModel.h5\"\n",
    "STOCK_LASER_IMAGE = \"online_model/files/example_input_image.npy\"\n",
    "\n",
    "MODEL_KWARGS = {\n",
    "    \"model_file\": MODEL_FILE,\n",
    "    \"stock_image_input\": np.load(STOCK_LASER_IMAGE),\n",
    "}\n",
    "\n",
    "ARRAY_PVS = [\"x:y\"]\n",
    "\n",
    "\n",
    "\n",
    "def pvdb_from_xarray(dset, protocol):\n",
    "    input_pvdb = {}\n",
    "    output_pvdb = {}\n",
    "\n",
    "    for variable in dset.keys():\n",
    "\n",
    "        entry = {\n",
    "            \"prec\": dset[variable].attrs[\"precision\"],\n",
    "            \"units\": dset[variable].attrs[\"units\"],\n",
    "            \"range\": dset[variable].attrs[\"range\"],\n",
    "            \"type\": \"float\",  # For channel access\n",
    "        }\n",
    "\n",
    "        # set up area detector pvs\n",
    "        if protocol == \"ca\" and dset[variable].attrs[\"pv_type\"] == \"image\":\n",
    "            image_pvs = build_image_pvs(\n",
    "                variable,\n",
    "                dset[variable].attrs[\"shape\"],\n",
    "                dset[variable].attrs[\"units\"],\n",
    "                dset[variable].attrs[\"precision\"],\n",
    "                dset[variable].attrs[\"color_mode\"],\n",
    "            )\n",
    "\n",
    "            if dset[variable].attrs[\"is_input\"] == 1:\n",
    "                input_pvdb.update(image_pvs)\n",
    "\n",
    "            elif dset[variable].attrs[\"is_input\"] == 0:\n",
    "                output_pvdb.update(image_pvs)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if dset[variable].attrs[\"is_input\"]:\n",
    "\n",
    "                # set values for the inputs\n",
    "                if dset[variable].attrs[\"pv_type\"] == \"scalar\":\n",
    "                    entry[\"value\"] = dset[variable].values[\n",
    "                        0\n",
    "                    ]  # Have to extract our scalar value from the xarray\n",
    "\n",
    "                else:\n",
    "                    entry[\"value\"] = dset[variable]\n",
    "\n",
    "                input_pvdb[variable] = entry\n",
    "\n",
    "            else:\n",
    "                output_pvdb[variable] = entry\n",
    "\n",
    "    return input_pvdb, output_pvdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to file\n",
    "import pickle\n",
    "\n",
    "with open(\"online_model/files/xarray_dset.pickle\",  \"wb\") as f:\n",
    "    pickle.dump(dset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Channel Access Server\n",
    "Note: The `build_image_pvs` function used below is a utility function that adds the appropriate image process variables for the AreaDetector naming scheme. This will ultimately be included in the initial pvdb construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_model.util import build_image_pvs\n",
    "from online_model.server import ca\n",
    "\n",
    "input_pvdb, output_pvdb = pvdb_from_xarray(dset, \"ca\")\n",
    "\n",
    "server = ca.CAServer(MySurrogateModel, MODEL_KWARGS, input_pvdb, output_pvdb, PREFIX, ARRAY_PVS)\n",
    "server.start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PVAccess server\n",
    "(works with Server.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_model.server import pva\n",
    "\n",
    "input_pvdb, output_pvdb = pvdb_from_xarray(dset, \"pva\")\n",
    "\n",
    "server = pva.PVAServer(MySurrogateModel, MODEL_KWARGS, input_pvdb, output_pvdb, PREFIX, ARRAY_PVS)\n",
    "server.start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build variables using pydantic classes\n",
    "Pydantic is a library which enforces type hinting at runtime. This means that errors in variable configurations can be caught during variable construction. Pydantic also gives control over dictionary conversions and json schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from enum import Enum\n",
    "from typing import Any, List, Union, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# custom validator for ndarrays\n",
    "class NumpyNDArray(np.ndarray):\n",
    "    @classmethod\n",
    "    def __get_validators__(cls):\n",
    "        yield cls.validate\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, v: Any) -> np.ndarray:\n",
    "        # validate data...\n",
    "        if not isinstance(v, np.ndarray):\n",
    "            raise TypeError(\"Numpy array required\")\n",
    "        return v\n",
    "    \n",
    "\n",
    "class IOEnum(str, Enum):\n",
    "    pv_in = \"input\"\n",
    "    pv_out = \"output\"\n",
    "\n",
    "\n",
    "class ProcessVariable(BaseModel):\n",
    "    name: str\n",
    "    io_type: IOEnum  # requires selection of input or output for creation\n",
    "    # defaults for pvdb\n",
    "    value_type: str = Field(\"float\", alias = \"type\")\n",
    "    precision: int = 8\n",
    "\n",
    "    class Config:\n",
    "        use_enum_values = True\n",
    "\n",
    "\n",
    "class ScalarProcessVariable(ProcessVariable):\n",
    "    value: Optional[float]\n",
    "    default: Optional[float]\n",
    "        \n",
    "    # alias allows us to define dict representation\n",
    "    value_range: list = Field(alias=\"range\") \n",
    "    units: Optional[str]\n",
    "\n",
    "\n",
    "class NDProcessVariable(ProcessVariable):\n",
    "    value: Optional[NumpyNDArray]\n",
    "    default: Optional[NumpyNDArray]\n",
    "        \n",
    "    # alias allows us to define dict representation\n",
    "    value_range: list = Field(alias=\"range\") \n",
    "    units: str\n",
    "\n",
    "\n",
    "class ImageProcessVariable(NDProcessVariable):\n",
    "    color_mode: int = 0\n",
    "    shape: tuple  # need for channel access AreaDetector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of an incorrectly typed prcess variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_var = ScalarProcessVariable(\n",
    "                    name=\"test\", \n",
    "                    io_type = \"input\", \n",
    "                    units=\"test\", \n",
    "                    value=5.0, \n",
    "                    default= np.ndarray([5,  2],), # for a scalar parameter, a float should be passed\n",
    "                    range=[5, 4]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a correctly typed variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param = ScalarProcessVariable(\n",
    "                    name=\"test\", \n",
    "                    io_type = \"input\", \n",
    "                    units=\"test_units\", \n",
    "                    value=5.0, \n",
    "                    default=0.0, # for a scalar parameter, a float should be passed\n",
    "                    range=[5, 4]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary representation can be used directly to build the pvdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param.dict(exclude_unset=True, exclude={\"io_type\"}, by_alias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar to the xarray config, we can use classes to set up process variables on a case by case basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = []\n",
    "\n",
    "for variable, configs in VARIABLES.items():\n",
    "    \n",
    "    if configs[\"is_input\"] == 1:\n",
    "        io_type = \"input\"\n",
    "        \n",
    "    else:\n",
    "        io_type = \"output\"\n",
    "    \n",
    "    \n",
    "    if configs[\"pv_type\"] == \"scalar\":\n",
    "        var = ScalarProcessVariable(\n",
    "            name = variable,\n",
    "            io_type = io_type,\n",
    "            **configs\n",
    "        )\n",
    "    \n",
    "    elif configs[\"pv_type\"] == \"image\":\n",
    "        var =  NDProcessVariable(\n",
    "            name = variable,\n",
    "            io_type = io_type,\n",
    "            **configs\n",
    "        )\n",
    "    \n",
    "    variables.append(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pvdb from the class instances:\n",
    "\n",
    "Besides the channel access image variables, the pvdb entries are created simply by calling the dict method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvdb_from_classes(variables, protocol):\n",
    "    input_pvdb = {}\n",
    "    output_pvdb = {}\n",
    "\n",
    "    for variable in variables:\n",
    "        # no manual formatting needed and have control over what is included/excluded\n",
    "        # by_alias kwarg allows us to dump the dict using reserved types\n",
    "        entry = variable.dict(exclude_unset=True, exclude={\"io_type\"}, by_alias=True)\n",
    "\n",
    "        if protocol == \"ca\" and isinstance(variable, (ImageProcessVariable,)):\n",
    "            image_pvs = build_image_pvs(\n",
    "                variable.name,\n",
    "                variable.shape,\n",
    "                variable.units,\n",
    "                variable.precision,\n",
    "                variable.color_mode,\n",
    "            )\n",
    "\n",
    "            if variable.io_type == \"input\":\n",
    "                input_pvdb.update(image_pvs)\n",
    "\n",
    "            elif variable.io_type == \"output\":\n",
    "                output_pvdb.update(image_pvs)\n",
    "\n",
    "        else:\n",
    "            if variable.io_type == \"input\":\n",
    "                input_pvdb[variable.name] = entry\n",
    "\n",
    "            elif variable.io_type == \"output\":\n",
    "                output_pvdb[variable.name] = entry\n",
    "\n",
    "            else:\n",
    "                # pydantic enum validation will prohibit any other assignment\n",
    "                pass\n",
    "\n",
    "    return input_pvdb, output_pvdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Channel Access Server\n",
    "Note: The `build_image_pvs` function used below is a utility function that adds the appropriate image process variables for the AreaDetector naming scheme. This will ultimately be included in the initial pvdb construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_model.server import ca\n",
    "\n",
    "input_pvdb, output_pvdb = pvdb_from_classes(variables, \"ca\")\n",
    "\n",
    "server = ca.CAServer(MySurrogateModel, MODEL_KWARGS, input_pvdb, output_pvdb, PREFIX, ARRAY_PVS)\n",
    "server.start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PVAccess Server \n",
    "(works with Server.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_model.server import pva\n",
    "\n",
    "input_pvdb, output_pvdb = pvdb_from_classes(variables, \"pva\")\n",
    "\n",
    "server = pva.PVAServer(MySurrogateModel, MODEL_KWARGS, input_pvdb, output_pvdb, PREFIX, ARRAY_PVS)\n",
    "server.start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Conclusions\n",
    "\n",
    "There are a couple of strange things about the xarray implementation.\n",
    "- The array dimension field is unused in our server/client famework; however, xarray variables require dimension definition. This forced assignment contradicts could contradict quantity standards (like openPMD, though this is admittedly pedantic). \n",
    "- A value field must be passed to construct the array. This isn't consistent with how output variables are used currently as they don't require values for initial construction.\n",
    "- Scalar process variables must be passed as an array and then sampled to extract value\n",
    "- In order to access the indexing features of xarray, a strict pythonic naming scheme has to be enforced for the input/output names (For example, `data_set.laser_radius.value`, vs, `data_set\\[\"phi(1)\"\\].value`). Use of pythonic aliases for the variables within the xarray structure could be augmented by an attribute with the proper name; though, this is redundant and probably would lead to confusion.\n",
    "- Addition of new attribute = more function arguments, which could expand dramatically depending on the amount of client-building automation desired. \n",
    "\n",
    "\n",
    "## Beyond server config\n",
    "Other configurations will be needed in order to expand this framework beyond the current model implementation. On the client side, instructions for rendering must be passed on the basis of process variable type. In order to do this, the type of the variable must be known. With xarray this requires the introspection of attributes for each variable. With the class implementation, this could be enforced with a type validation on the process variable class. \n",
    "\n",
    "Client-side configurations will also require the abstraction of indicators that are currently hard-coded. For example, slider inclusion/exclusion will need to be abstracted before accomodating other models. This could be accomplished by an exposure attribute or by the optional inclusion of SliderConfig settings, that could enforce additional range constraints, set the step size, etc.. Other controls may be required beyond sliders, each with their own, specific and sometimes optional settings. Pydantic models are well suited to this application and may be favorable over attribute expansion in xarray.\n",
    "\n",
    "# Other considerations\n",
    "\n",
    "- How will these inputs and outputs be saved? \n",
    "These input and output variables need to be decopled from the current hdf5 in order for the client to operate without a distribution of the the original model\n",
    "\n",
    "![title](online_model/files/program_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online-surrogate-model-dev",
   "language": "python",
   "name": "online-surrogate-model-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
